import os
import re
import hashlib
import json
import logging
from typing import List, Tuple, Optional, Dict, Any
from fastapi import FastAPI, UploadFile, File, HTTPException, Form
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_tavily import TavilySearch
import pymysql

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

# ==========================================================
# í™˜ê²½ ì„¤ì • ë° ì´ˆê¸°í™”
# ==========================================================
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
DB_HOST = os.getenv("DB_HOST")
DB_PORT = int(os.getenv("DB_PORT", "3306"))
DB_DATABASE = os.getenv("DB_DATABASE")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")

if not OPENAI_API_KEY:
    raise ValueError("âŒ OPENAI_API_KEY ë¯¸ì„¤ì •!")

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2, api_key=OPENAI_API_KEY)
embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)
tavily_tool = TavilySearch(api_key=TAVILY_API_KEY, max_results=3) if TAVILY_API_KEY else None

app = FastAPI(title="PDF í•™ìŠµ ë„ìš°ë¯¸ API")

origins = [
    "http://localhost:5173",
    "http://127.0.0.1:5173",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],
)

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# ==========================================================
# ğŸ”§ ì—…ë¡œë“œ ê²½ë¡œ ìë™ ë¶„ê¸° (ë¡œì»¬/ë°°í¬ ëª¨ë‘ ëŒ€ì‘)
# ==========================================================
if os.getenv("ENV_MODE", "local") == "prod":
    UPLOAD_DIR = "/uploads"  # âœ… Docker(ë°°í¬) í™˜ê²½
else:
    UPLOAD_DIR = os.path.join(os.getcwd(), "uploaded_pdfs")  # âœ… ë¡œì»¬ ì‹¤í–‰ ì‹œ

VECTOR_DIR = "vector_stores"
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(VECTOR_DIR, exist_ok=True)

# ==========================================================
# Pydantic ëª¨ë¸ ì •ì˜
# ==========================================================
class PdfPathsRequest(BaseModel):
    pdf_paths: List[str]

class ChapterRequest(BaseModel):
    pdf_paths: Optional[List[str]] = None
    chapter_request: Optional[str] = None

class QuestionRequest(BaseModel):
    question: str
    force_web: bool
    pdf_paths: Optional[List[str]] = None

class QuizGenerationRequest(BaseModel):
    pdf_paths: List[str]
    num_questions: int = Field(5, ge=1, le=20)
    difficulty: str = Field("MEDIUM", pattern="^(EASY|MEDIUM|HARD)$")

# ==========================================================
# PDF ìœ í‹¸ í•¨ìˆ˜
# ==========================================================
def extract_text_from_pdf(pdf_path: str) -> str:
    try:
        loader = PyPDFLoader(pdf_path)
        pages = loader.load()
        return "\n".join([p.page_content for p in pages])
    except Exception as e:
        logger.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {pdf_path} | {e}")
        return ""

def get_or_create_vectorstore(pdf_path: str) -> Optional[FAISS]:
    normalized_path = pdf_path.replace("\\", "/")
    path_hash = hashlib.md5(normalized_path.encode()).hexdigest()
    vector_path = os.path.join(VECTOR_DIR, path_hash)
    if os.path.exists(vector_path):
        return FAISS.load_local(vector_path, embeddings, allow_dangerous_deserialization=True)
    try:
        loader = PyPDFLoader(pdf_path)
        texts = [p.page_content for p in loader.load()]
        vs = FAISS.from_texts(texts, embeddings)
        vs.save_local(vector_path)
        logger.info(f"âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ: {pdf_path}")
        return vs
    except Exception as e:
        logger.error(f"âŒ ë²¡í„° ìƒì„± ì‹¤íŒ¨ ({pdf_path}): {e}")
        return None

def combine_vectorstores(pdf_paths: List[str]) -> Tuple[Optional[FAISS], Optional[str]]:
    vectorstores = []
    combined_content = ""
    for pdf_path in pdf_paths:
        if not os.path.exists(pdf_path):
            continue
        vs = get_or_create_vectorstore(pdf_path)
        if vs:
            vectorstores.append(vs)
            combined_content += extract_text_from_pdf(pdf_path) + "\n\n--- PDF ë¶„ë¦¬ ---\n\n"
    if not vectorstores:
        return None, None
    main_vs = vectorstores[0]
    for i in range(1, len(vectorstores)):
        main_vs.merge_from(vectorstores[i])
    return main_vs, combined_content.strip()

# ==========================================================
# ì±•í„° ê°ì§€
# ==========================================================
def detect_chapters_by_regex(text: str) -> List[str]:
    patterns = [
        r"ì œ\s*\d+\s*ì¥",
        r"CHAPTER\s+\d+",
        r"Chapter\s+\d+",
        r"\b\d+\.\d+",
        r"Section\s+\d+",
        r"Part\s+[IVXLC\d]+"
    ]
    found = set()
    for p in patterns:
        matches = re.findall(p, text)
        for m in matches:
            found.add(m.strip())
    return sorted(found)

def detect_chapters_by_llm(text: str) -> List[str]:
    prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì±•í„° ì œëª©ì„ ìˆœì„œëŒ€ë¡œ ë½‘ì•„ì£¼ì„¸ìš”.
ì˜ˆì‹œ ì¶œë ¥: ["ì œ1ì¥ ê°œìš”", "ì œ2ì¥ ì´ë¡ "]
---
{text[:4000]}
"""
    try:
        response = llm.invoke(prompt)
        lines = re.findall(r"ì œ?\s*\d+\s*ì¥|CHAPTER\s+\d+|Chapter\s+\d+|\d+\.\d+", response.content)
        return sorted(set(lines))
    except Exception as e:
        logger.warning(f"âš ï¸ LLM ì±•í„° ê°ì§€ ì‹¤íŒ¨: {e}")
        return []

def get_total_chapters(text: str) -> Dict[str, Any]:
    regex_chapters = detect_chapters_by_regex(text)
    if regex_chapters:
        return {"method": "regex", "total_chapters": len(regex_chapters), "chapter_list": regex_chapters}
    llm_chapters = detect_chapters_by_llm(text)
    if llm_chapters:
        return {"method": "llm", "total_chapters": len(llm_chapters), "chapter_list": llm_chapters}
    return {"method": "none", "total_chapters": 1, "chapter_list": []}

# ==========================================================
# DB ì¡°íšŒ
# ==========================================================
def get_pdf_paths_for_content(content_id: int):
    connection = None
    paths = []
    try:
        connection = pymysql.connect(
            host=DB_HOST,
            port=DB_PORT,
            user=DB_USER,
            password=DB_PASSWORD,
            database=DB_DATABASE,
            charset='utf8mb4',
            cursorclass=pymysql.cursors.DictCursor
        )
        with connection.cursor() as cursor:
            sql = "SELECT file_path FROM contents WHERE id=%s"
            cursor.execute(sql, (content_id,))
            result = cursor.fetchall()
            paths = [row['file_path'] for row in result if row['file_path']]
    except Exception as e:
        logger.error(f"âŒ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
    finally:
        if connection:
            connection.close()
    return paths

# ==========================================================
# FastAPI ì—”ë“œí¬ì¸íŠ¸
# ==========================================================
app = FastAPI(title="PDF í•™ìŠµ ë„ìš°ë¯¸ API (Full í†µí•©)")

@app.get("/health/")
async def health_check():
    return {"status": "ok"}

# ì´í•˜ ë‚˜ë¨¸ì§€ ì—”ë“œí¬ì¸íŠ¸ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
# /upload_pdfs, /summarize, /ask, /quiz/generate ë“±...
