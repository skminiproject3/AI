import os
import re
import hashlib
from typing import List, Tuple, Optional, Dict, Any
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Depends
from fastapi.responses import JSONResponse
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain.prompts import PromptTemplate
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_community.vectorstores import FAISS
from pydantic import BaseModel, Field
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# ====== Pydantic ëª¨ë¸ ì •ì˜ ======
class PdfPathsRequest(BaseModel):
    pdf_paths: List[str]

class QuestionRequest(BaseModel):
    question: str
    pdf_paths: List[str]

class QuizGenerationRequest(BaseModel):
    pdf_paths: List[str]
    num_questions: int = Field(5, ge=1, le=20)
    difficulty: str = Field("MEDIUM", pattern="^(EASY|MEDIUM|HARD)$")

class QuizAnswer(BaseModel):
    question_text: str  # ì§ˆë¬¸ ì›ë¬¸
    user_answer: str    # ì‚¬ìš©ì ë‹µë³€

class QuizGradingRequest(BaseModel):
    pdf_paths: List[str]
    answers: List[QuizAnswer]
    # score_per_question: int = Field(20) # ë°±ì—”ë“œì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ì œê±°

# ====== í™˜ê²½ ì„¤ì • ======
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2, api_key=OPENAI_API_KEY)
embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)

# Tavily ë„êµ¬ ì´ˆê¸°í™” (API Keyê°€ ì—†ìœ¼ë©´ None)
tavily_tool = TavilySearchResults(api_key=TAVILY_API_KEY, max_results=3) if TAVILY_API_KEY else None

app = FastAPI(title="PDF í•™ìŠµ ë„ìš°ë¯¸ API")

# ===============================================
# ====== Core Functions (PDF/Vector/Text Processing) ======
# ===============================================

def extract_text_from_pdf(pdf_path: str) -> str:
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        loader = PyPDFLoader(pdf_path)
        pages = loader.load()
        return "\n".join([p.page_content for p in pages])
    except Exception as e:
        logger.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ({pdf_path}): {e}")
        return ""

def get_or_create_vectorstore(pdf_path: str) -> Optional[FAISS]:
    """PDF ê²½ë¡œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤."""
    base_vector_dir = "vector_stores"
    normalized_path = pdf_path.replace('\\', '/')
    path_hash = hashlib.md5(normalized_path.encode()).hexdigest()
    vector_path = os.path.join(base_vector_dir, path_hash)

    if not os.path.exists(base_vector_dir):
        os.makedirs(base_vector_dir)

    if os.path.exists(vector_path):
        return FAISS.load_local(vector_path, embeddings, allow_dangerous_deserialization=True)
    else:
        logger.info(f"ğŸ”„ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹œì‘: {pdf_path}")
        try:
            loader = PyPDFLoader(pdf_path)
            pages = loader.load()
            texts = [p.page_content for p in pages]
            if not texts:
                logger.warning(f"ê²½ê³ : {pdf_path}ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return None
            vectorstore = FAISS.from_texts(texts, embeddings)
            vectorstore.save_local(vector_path)
            logger.info(f"âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥ ì™„ë£Œ: {pdf_path}")
            return vectorstore
        except Exception as e:
            logger.error(f"âŒ ë²¡í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({pdf_path}): {e}")
            return None

def combine_vectorstores(pdf_paths: List[str]) -> Tuple[Optional[FAISS], Optional[str]]:
    """ë‹¤ì¤‘ PDF ê²½ë¡œì—ì„œ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë³‘í•©í•˜ê³  ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    vectorstores = []
    combined_content = ""
    
    for pdf_path in pdf_paths:
        if not os.path.exists(pdf_path):
            logger.warning(f"âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤: {pdf_path}")
            continue

        vs = get_or_create_vectorstore(pdf_path)
        if vs:
            vectorstores.append(vs)
            content = extract_text_from_pdf(pdf_path)
            combined_content += content + "\n\n--- PDF ë¶„ë¦¬ ë§ˆì»¤ ---\n\n"
            
    if not vectorstores:
        logger.error("âŒ ìœ íš¨í•œ PDF íŒŒì¼ì´ ì—†ì–´ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë³‘í•©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
        
    main_vs = vectorstores[0]
    for i in range(1, len(vectorstores)):
        main_vs.merge_from(vectorstores[i])
        
    return main_vs, combined_content.strip()

def split_by_subchapter(text: str) -> Dict[str, str]:
    """í…ìŠ¤íŠ¸ì—ì„œ 'ìˆ«ì.ìˆ«ì' í˜•íƒœ(ì˜ˆ: 2.1)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤."""
    pattern = r"(?=(\d+\.\d+))"
    splits = re.split(pattern, text)
    chapters = {}
    current_chapter = None
    for seg in splits:
        if re.match(r"\d+\.\d+", seg.strip()):
            current_chapter = seg.strip()
            chapters[current_chapter] = ""
        elif current_chapter:
            chapters[current_chapter] += seg.strip() + "\n"
    return chapters

# ===============================================
# ====== LLM Prompts and Functions (Summary & Quiz) ======
# ===============================================

summary_prompt = PromptTemplate(
    input_variables=["content"],
    template="""
ë‹¹ì‹ ì€ êµì¬ì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë‚´ìš©ì„ í•µì‹¬ ê°œë… ì¤‘ì‹¬ìœ¼ë¡œ ê°„ê²°í•˜ê³  ëª…ë£Œí•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”.

- ì£¼ìš” ê°œë… 3~5ê°œ ì¤‘ì‹¬
- ê³µì‹, ì •ì˜, íŠ¹ì§• í¬í•¨

ë‚´ìš©:
{content}

ì¶œë ¥ í˜•ì‹:
---
[ìš”ì•½]
1. ...
2. ...
3. ...
---
"""
)

quiz_generation_prompt = PromptTemplate(
    input_variables=["content", "num_questions", "difficulty"],
    template="""
ë‹¤ìŒ êµì¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {num_questions}ê°œì˜ **4ì§€ì„ ë‹¤ ê°ê´€ì‹ ë¬¸ì œ**ë¥¼ ì¶œì œí•˜ì„¸ìš”.
**(ì°¸ê³ : ë‚´ìš©ì€ ì—¬ëŸ¬ PDF íŒŒì¼ì—ì„œ ê²°í•©ëœ ê²ƒì¼ ìˆ˜ ìˆìœ¼ë©°, ë‚œì´ë„ëŠ” {difficulty} ì…ë‹ˆë‹¤.)**

- ëª¨ë“  ë¬¸í•­ì€ ë°˜ë“œì‹œ **ë³´ê¸° a), b), c), d)** ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
- ê° ë¬¸í•­ì€ í•˜ë‚˜ì˜ ëª…í™•í•œ ì •ë‹µì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.
- ì •ë‹µ í‘œì‹œë‚˜ '(ì •ë‹µ: ...)'ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- ë¬¸ì œ ì¤‘ë³µ ê¸ˆì§€

ë‚´ìš©:
{content}

ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:
---
[ì—°ìŠµë¬¸ì œ]
1. ë‹¤ìŒ ì¤‘ ...ì— ëŒ€í•œ ì„¤ëª…ìœ¼ë¡œ ì˜³ì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€?
a) ...
b) ...
c) ...
d) ...
2. ...
a) ...
b) ...
c) ...
d) ...
---
"""
)

grading_prompt = PromptTemplate(
    input_variables=["question", "user_answer", "context"],
    template="""
ë‹¹ì‹ ì€ ì£¼ì–´ì§„ 'êµì¬ ë‚´ìš©'ì—ë§Œ ê·¼ê±°í•˜ì—¬ í€´ì¦ˆë¥¼ ì±„ì í•˜ëŠ” AI ì¡°êµì…ë‹ˆë‹¤. ì™¸ë¶€ ì§€ì‹ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

**[ì±„ì  ì ˆì°¨]**
1. **ì •ë‹µ ì°¾ê¸°**: 'êµì¬ ë‚´ìš©'ì—ì„œ 'ë¬¸ì œ'ì— ëŒ€í•œ ëª…í™•í•œ ì •ë‹µì„ ì°¾ìŠµë‹ˆë‹¤.
2. **ë‹µë³€ ë¹„êµ**: 'ì‚¬ìš©ì ë‹µë³€'ì„ ì •ë‹µê³¼ ë¹„êµí•©ë‹ˆë‹¤.
   - ê°ê´€ì‹ ë¬¸ì œ: **ì‚¬ìš©ì ë‹µë³€ì´ 'b) í‚¤ êµí™˜' í˜•íƒœì´ê±°ë‚˜ ë‹¨ìˆœíˆ 'b' ë˜ëŠ” 'b)'ì™€ ê°™ì´ ì •ë‹µ ì„ íƒì§€ ë²ˆí˜¸ë§Œ í¬í•¨í•˜ëŠ” ê²½ìš° ëª¨ë‘ ì •ë‹µìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.**
3. **ì¶œë ¥ í˜•ì‹ ì¤€ìˆ˜**: ì±„ì  ê²°ê³¼ë¥¼ ì•„ë˜ 'ì¶œë ¥ í˜•ì‹'ì— ë§ì¶° ì •í™•í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤.

---
**êµì¬ ë‚´ìš© (Source of Truth):**
{context}
---
**ë¬¸ì œ:**
{question}
---
**ì‚¬ìš©ì ë‹µë³€:**
{user_answer}
---
**[ì±„ì  ê²°ê³¼ ì¶œë ¥]**
ì •ë‹µì—¬ë¶€: [ì •ë‹µ/ì˜¤ë‹µ]
ì •ë‹µ: [êµì¬ ë‚´ìš©ì— ê·¼ê±°í•œ ëª…í™•í•˜ê³  ê°„ê²°í•œ ì •ë‹µì„ ì—¬ê¸°ì— ì„œìˆ  (ì˜ˆ: b) í‚¤ êµí™˜)]
ì„¤ëª…: [ì‚¬ìš©ì ë‹µë³€ì´ ì •ë‹µì¸ ì´ìœ , ë˜ëŠ” ì˜¤ë‹µì¸ ê²½ìš° ì •í™•í•œ ì„¤ëª…]
"""
)

def summarize_pdf_content(content: str) -> str:
    """ì „ì²´ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤."""
    prompt = summary_prompt.format(content=content[:10000]) # 4000ìì—ì„œ 10000ìë¡œ í™•ì¥
    result = llm.invoke(prompt)
    return result.content.strip()

def summarize_subchapters(content: str, request_chapter: Optional[str] = None) -> Tuple[List[Dict[str, str]], str]:
    """ë‹¨ì›ë³„ ìš”ì•½ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    chapters = split_by_subchapter(content)
    if not chapters:
        return [], "âŒ ë¬¸ì„œì—ì„œ ì†Œë‹¨ì›(ì˜ˆ: 4.1)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    summaries = []
    
    # 1. íŠ¹ì • ë‹¨ì› ìš”ì²­ (ì˜ˆ: '4.1ì¥' ë˜ëŠ” '4ì¥')
    if request_chapter:
        req = request_chapter.strip().lower()
        matched_keys = []
        
        # ìˆ«ì.ìˆ«ì íŒ¨í„´ ìš°ì„ 
        m_dot = re.search(r"(\d+\.\d+)", req)
        if m_dot:
            key = m_dot.group(1)
            if key in chapters:
                matched_keys.append(key)
        
        # ìˆ«ì íŒ¨í„´ (ìƒìœ„ ì¥)
        m_major = re.search(r"(\d+)", req)
        if not matched_keys and m_major:
            major = m_major.group(1) 
            matched_keys = sorted([k for k in chapters.keys() if k.startswith(f"{major}.")])
            
        if not matched_keys:
            return [], f"âŒ ìš”ì²­í•œ ë‹¨ì› '{request_chapter}' ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ë§¤ì¹­ëœ ë‹¨ì›ë“¤ë§Œ ê²°í•© ë° ìš”ì•½
        combined = "\n\n".join([chapters[k] for k in matched_keys])
        summary = summarize_pdf_content(combined)
        summaries.append({"chapter": ", ".join(matched_keys), "summary": summary})
        
        return summaries, "âœ… ìš”ì²­ëœ ë‹¨ì› ìš”ì•½ ì™„ë£Œ"

    # 2. ì „ì²´ ë‹¨ì› ìš”ì•½ ìš”ì²­ (request_chapterê°€ Noneì¼ ë•Œ)
    for key, text in chapters.items():
        summary = summarize_pdf_content(text)
        summaries.append({"chapter": key, "summary": summary})
        
    return summaries, "âœ… ë‹¨ì›ë³„ ì „ì²´ ìš”ì•½ ì™„ë£Œ"


# ===============================================
# ====== FastAPI Endpoints ======
# ===============================================

@app.get("/health/")
async def health_check():
    return {"status": "ok"}

@app.post("/upload_pdfs/")
async def upload_pdfs(files: List[UploadFile] = File(...)):
    """PDF íŒŒì¼ì„ ë°›ì•„ ì €ì¥í•˜ê³ , ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±/ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    pdf_paths = []
    
    for file in files:
        save_dir = "uploaded_pdfs"
        save_path = os.path.join(save_dir, file.filename)
        os.makedirs(save_dir, exist_ok=True)
        
        try:
            with open(save_path, "wb") as f:
                f.write(await file.read())
            pdf_paths.append(save_path)
        except Exception as e:
            logger.error(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {file.filename} - {e}")
            raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {file.filename}")

    vectorstore, _ = combine_vectorstores(pdf_paths)
    
    if not vectorstore:
        raise HTTPException(status_code=400, detail="ìœ íš¨í•œ PDF íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
    return {"message": "PDF ì—…ë¡œë“œ ë° ë²¡í„° ìƒì„± ì™„ë£Œ", "pdf_paths": pdf_paths} 

# -----------------------------------------------
# ìš”ì•½ ì—”ë“œí¬ì¸íŠ¸
# -----------------------------------------------

@app.post("/summarize/full")
async def summarize_full(request: PdfPathsRequest):
    """ì „ì²´ ì½˜í…ì¸  í†µí•© ìš”ì•½."""
    _, content = combine_vectorstores(request.pdf_paths)
    
    if not content:
        raise HTTPException(status_code=400, detail="PDF ë‚´ìš©ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
    summary = summarize_pdf_content(content)
    return {"summary": summary}

@app.post("/summarize/chapter")
async def summarize_chapter(request: PdfPathsRequest, chapter_request: str = Form(None)):
    """ë‹¨ì›ë³„ ìš”ì•½ (ì „ì²´ ë˜ëŠ” íŠ¹ì • ë‹¨ì› ìš”ì²­)."""
    _, content = combine_vectorstores(request.pdf_paths)
    
    if not content:
        raise HTTPException(status_code=400, detail="PDF ë‚´ìš©ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    # chapter_requestê°€ Noneì´ë©´ ì „ì²´ ë‹¨ì› ìš”ì•½, ê°’ì´ ìˆìœ¼ë©´ íŠ¹ì • ë‹¨ì› ìš”ì•½ ì‹œë„
    summaries, message = summarize_subchapters(content, request_chapter=chapter_request)
    
    if not summaries:
         raise HTTPException(status_code=404, detail=message)
         
    return {"message": message, "summaries": summaries}

# -----------------------------------------------
# ì§ˆë¬¸ ë‹µë³€ ì—”ë“œí¬ì¸íŠ¸
# -----------------------------------------------

@app.post("/question/")
async def question_endpoint(request: QuestionRequest):
    """ì§ˆë¬¸ ë‹µë³€ (RAG + Web Search Fallback)."""
    question = request.question
    vectorstore, _ = combine_vectorstores(request.pdf_paths)
    
    if not vectorstore:
        raise HTTPException(status_code=400, detail="PDF ë²¡í„° ë¡œë“œ ì‹¤íŒ¨. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
    # 1. RAG ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
    docs = vectorstore.similarity_search(question, k=4)
    vector_context = "\n".join([d.page_content for d in docs])
    
    web_context = ""
    
    # 2. ë²¡í„° ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡± ì‹œ (ë¬¸ì„œ 1ê°œ ë¯¸ë§Œ), Tavily ì›¹ ê²€ìƒ‰ ì‹œë„
    if len(docs) < 1 and tavily_tool:
        logger.info("âš ï¸ ë²¡í„° ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡±. Tavily ì›¹ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤.")
        try:
            search_results = tavily_tool.run(question)
            web_context = "\n\n--- ì›¹ ê²€ìƒ‰ ê²°ê³¼ ---\n\n"
            for result in search_results:
                 if 'content' in result:
                    web_context += f"ì¶œì²˜: {result.get('url', 'N/A')}\në‚´ìš©: {result['content']}\n\n"
                 elif 'snippet' in result:
                     web_context += f"ì¶œì²˜: {result.get('url', 'N/A')}\në‚´ìš©: {result['snippet']}\n\n"
            
            if web_context.strip().endswith("--- ì›¹ ê²€ìƒ‰ ê²°ê³¼ ---"):
                 web_context = "" # ìœ íš¨í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì—ˆì„ ê²½ìš°
                 
        except Exception as e:
            logger.error(f"Tavily ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            web_context = ""

    # 3. ë‹µë³€ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    final_context = f"--- êµì¬(PDF) ë‚´ìš© ---\n{vector_context}\n{web_context}"
    
    prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì œê³µí•œ êµì¬ ë‚´ìš©ê³¼ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. 

    - êµì¬ ë‚´ìš©(PDF)ì´ ìˆë‹¤ë©´ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
    - êµì¬ ë‚´ìš©ë§Œìœ¼ë¡œ ë‹µë³€ì´ ì–´ë µê±°ë‚˜, êµì¬ ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
    - ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í–ˆì„ ê²½ìš°, ë‹µë³€ ë§ë¯¸ì— 'ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì°¸ê³ ë˜ì—ˆìŠµë‹ˆë‹¤.'ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.
    
    ì œê³µëœ ëª¨ë“  ì»¨í…ìŠ¤íŠ¸:
    {final_context}
    
    ì§ˆë¬¸: {question}
    
    ë‹µë³€:"""
    
    # 4. LLM í˜¸ì¶œ
    result = llm.invoke(prompt)
    answer = result.content.strip()
    return {"answer": answer}

# -----------------------------------------------
# ì—°ìŠµë¬¸ì œ ì—”ë“œí¬ì¸íŠ¸
# -----------------------------------------------

@app.post("/quiz/generate")
async def quiz_generate(request: QuizGenerationRequest):
    """ê°ê´€ì‹ ì—°ìŠµë¬¸ì œ ìƒì„±."""
    _, content = combine_vectorstores(request.pdf_paths)
    
    if not content:
        raise HTTPException(status_code=400, detail="PDF ë‚´ìš©ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
    logger.info(f"ğŸ§© ë¬¸ì œ ìƒì„± ì‹œì‘: {request.num_questions}ë¬¸í•­, ë‚œì´ë„ {request.difficulty}")
    
    prompt = quiz_generation_prompt.format(
        content=content[:10000],
        num_questions=request.num_questions,
        difficulty=request.difficulty
    )
    
    result = llm.invoke(prompt)
    quiz_text = result.content.strip()
    
    # ë¬¸ì œ íŒŒì‹± (ì¶”ê°€ì ì¸ ì•ˆì •ì„±ì„ ìœ„í•´ íŒŒì‹± ë¡œì§ í¬í•¨)
    quiz_body = quiz_text.split('[ì—°ìŠµë¬¸ì œ]')[-1].strip()
    questions_raw = re.findall(r"\d+\.\s*(.*?)(?=\n\d+\.|\Z)", quiz_body, re.DOTALL)
    
    parsed_questions = []
    for q_text in questions_raw:
        q_clean = re.sub(r'^\s+|\s+$', '', q_text)
        # ë³´ê¸° ë¶„ë¦¬ ë¡œì§ì„ ì¶”ê°€í•  ìˆ˜ ìˆìœ¼ë‚˜, ì—¬ê¸°ì„œëŠ” í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ ì €ì¥í•˜ì—¬ ì±„ì  ì‹œ LLMì´ ì²˜ë¦¬í•˜ë„ë¡ ìœ ì§€
        parsed_questions.append({"question_text": q_clean})
        
    if not parsed_questions:
        logger.error("âŒ ë¬¸ì œ íŒŒì‹± ì‹¤íŒ¨. LLM ì¶œë ¥ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
        return {"quiz_text": quiz_text, "questions": []}

    return {"quiz_text": quiz_text, "questions": parsed_questions}

@app.post("/quiz/grade")
async def quiz_grade(request: QuizGradingRequest):
    """ì‚¬ìš©ìì˜ ë‹µë³€ì„ ì±„ì í•˜ê³  ê²°ê³¼ì™€ ì„¤ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    _, content = combine_vectorstores(request.pdf_paths)
    
    if not content:
        raise HTTPException(status_code=400, detail="PDF ë‚´ìš©ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    results = []
    total_score = 0
    correct_count = 0
    num_total_questions = len(request.answers)
    score_per_question = 100 // num_total_questions if num_total_questions > 0 else 0
    
    for ans in request.answers:
        grade_prompt_text = grading_prompt.format(
            question=ans.question_text,
            user_answer=ans.user_answer,
            context=content[:10000]
        )

        try:
            result = llm.invoke(grade_prompt_text)
            result_text = result.content.strip()

            # LLM ì‘ë‹µì—ì„œ ë°ì´í„° ì¶”ì¶œ
            is_correct_str_match = re.search(r"ì •ë‹µì—¬ë¶€:\s*([^\n]+)", result_text)
            correct_answer_match = re.search(r"ì •ë‹µ:\s*([^\n]+)", result_text, re.DOTALL)
            explanation_match = re.search(r"ì„¤ëª…:\s*([^\n]+)", result_text, re.DOTALL)

            is_correct = "ì •ë‹µ" in is_correct_str_match.group(1).strip() if is_correct_str_match else False
            correct_answer = correct_answer_match.group(1).strip() if correct_answer_match else "ì±„ì  ì˜¤ë¥˜: ì •ë‹µ ë¯¸í¬í•¨"
            explanation = explanation_match.group(1).strip() if explanation_match else "ì±„ì  ì˜¤ë¥˜: ì„¤ëª… ë¯¸í¬í•¨"

            score = score_per_question if is_correct else 0
            total_score += score
            if is_correct:
                correct_count += 1
            
            results.append({
                "question": ans.question_text,
                "user_answer": ans.user_answer,
                "correct_answer": correct_answer,
                "explanation": explanation,
                "is_correct": is_correct,
                "score": score
            })

        except Exception as e:
            logger.error(f"ì±„ì  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            results.append({
                "question": ans.question_text,
                "user_answer": ans.user_answer,
                "correct_answer": "ì‹œìŠ¤í…œ ì˜¤ë¥˜",
                "explanation": f"ì±„ì  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}",
                "is_correct": False,
                "score": 0
            })
            
    # ìµœì¢… ì ìˆ˜ ë³´ì • (100ì  ë§Œì ìœ¼ë¡œ)
    final_total_score = total_score
    remaining_score = 100 - (score_per_question * num_total_questions)
    
    if remaining_score > 0 and correct_count > 0:
        for res in reversed(results):
            if res['is_correct']:
                res['score'] += remaining_score
                final_total_score += remaining_score
                break
    
    if correct_count == 0:
        final_total_score = 0

    return {
        "final_total_score": final_total_score,
        "correct_count": correct_count,
        "total_questions": num_total_questions,
        "results": results
    }