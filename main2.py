import os
import re
import hashlib
import json
from typing import List, Tuple, Optional, Dict, Any
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Depends
from fastapi.responses import JSONResponse
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain.prompts import PromptTemplate
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_community.vectorstores import FAISS
from pydantic import BaseModel, Field
import logging
from typing import List, Optional
# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# ì—…ë¡œë“œ í´ë” ì •ì˜
UPLOAD_DIR = "uploaded_pdfs"
os.makedirs(UPLOAD_DIR, exist_ok=True)  # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±

# ====== Pydantic ëª¨ë¸ ì •ì˜ ======
class PdfPathsRequest(BaseModel):
    pdf_paths: List[str]
class ChapterRequest(BaseModel):
    pdf_paths: List[str]
    chapter_request: Optional[str] = None
class QuestionRequest(BaseModel):
    question: str
    pdf_paths: List[str]

class QuizGenerationRequest(BaseModel):
    pdf_paths: List[str]
    num_questions: int = Field(5, ge=1, le=20)
    difficulty: str = Field("MEDIUM", pattern="^(EASY|MEDIUM|HARD)$")

class QuizAnswer(BaseModel):
    question_text: str  # ì§ˆë¬¸ ì›ë¬¸
    user_answer: str    # ì‚¬ìš©ì ë‹µë³€

class QuizGradingRequest(BaseModel):
    pdf_paths: List[str]
    answers: List[QuizAnswer]
    # score_per_question: int = Field(20) # ë°±ì—”ë“œì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ì œê±°

# ====== í™˜ê²½ ì„¤ì • ======
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2, api_key=OPENAI_API_KEY)
embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)

# Tavily ë„êµ¬ ì´ˆê¸°í™” (API Keyê°€ ì—†ìœ¼ë©´ None)
tavily_tool = TavilySearchResults(api_key=TAVILY_API_KEY, max_results=3) if TAVILY_API_KEY else None

app = FastAPI(title="PDF í•™ìŠµ ë„ìš°ë¯¸ API")

# ===============================================
# ====== Core Functions (PDF/Vector/Text Processing) ======
# ===============================================

def extract_text_from_pdf(pdf_path: str) -> str:
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        loader = PyPDFLoader(pdf_path)
        pages = loader.load()
        return "\n".join([p.page_content for p in pages])
    except Exception as e:
        logger.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ({pdf_path}): {e}")
        return ""

def get_or_create_vectorstore(pdf_path: str) -> Optional[FAISS]:
    """PDF ê²½ë¡œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤."""
    base_vector_dir = "vector_stores"
    normalized_path = pdf_path.replace('\\', '/')
    path_hash = hashlib.md5(normalized_path.encode()).hexdigest()
    vector_path = os.path.join(base_vector_dir, path_hash)

    if not os.path.exists(base_vector_dir):
        os.makedirs(base_vector_dir)

    if os.path.exists(vector_path):
        return FAISS.load_local(vector_path, embeddings, allow_dangerous_deserialization=True)
    else:
        logger.info(f"ğŸ”„ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹œì‘: {pdf_path}")
        try:
            loader = PyPDFLoader(pdf_path)
            pages = loader.load()
            texts = [p.page_content for p in pages]
            if not texts:
                logger.warning(f"ê²½ê³ : {pdf_path}ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return None
            vectorstore = FAISS.from_texts(texts, embeddings)
            vectorstore.save_local(vector_path)
            logger.info(f"âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥ ì™„ë£Œ: {pdf_path}")
            return vectorstore
        except Exception as e:
            logger.error(f"âŒ ë²¡í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({pdf_path}): {e}")
            return None

def combine_vectorstores(pdf_paths: List[str]) -> Tuple[Optional[FAISS], Optional[str]]:
    vectorstores = []
    combined_content = ""
    
    for pdf_path in pdf_paths:
        if not os.path.exists(pdf_path):
            continue

        vs = get_or_create_vectorstore(pdf_path)
        if vs:
            vectorstores.append(vs)
            combined_content += extract_text_from_pdf(pdf_path) + "\n\n--- PDF ë¶„ë¦¬ ---\n\n"

    if not vectorstores:
        return None, None

    main_vs = vectorstores[0]
    for i in range(1, len(vectorstores)):
        main_vs.merge_from(vectorstores[i])

    return main_vs, combined_content.strip()


def split_by_subchapter(text: str) -> Dict[str, str]:
    """í…ìŠ¤íŠ¸ì—ì„œ 'ìˆ«ì.ìˆ«ì' í˜•íƒœ(ì˜ˆ: 2.1)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤."""
    pattern = r"(?=(\d+\.\d+))"
    splits = re.split(pattern, text)
    chapters = {}
    current_chapter = None
    for seg in splits:
        if re.match(r"\d+\.\d+", seg.strip()):
            current_chapter = seg.strip()
            chapters[current_chapter] = ""
        elif current_chapter:
            chapters[current_chapter] += seg.strip() + "\n"
    return chapters

# ===============================================
# ====== LLM Prompts and Functions (Summary & Quiz) ======
# ===============================================

summary_prompt = PromptTemplate(
    input_variables=["content"],
    template="""
ë‹¹ì‹ ì€ êµì¬ì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë‚´ìš©ì„ í•µì‹¬ ê°œë… ì¤‘ì‹¬ìœ¼ë¡œ ê°„ê²°í•˜ê³  ëª…ë£Œí•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”.

- ì£¼ìš” ê°œë… 3~5ê°œ ì¤‘ì‹¬
- ê³µì‹, ì •ì˜, íŠ¹ì§• í¬í•¨

ë‚´ìš©:
{content}

ì¶œë ¥ í˜•ì‹:
---
[ìš”ì•½]
1. ...
2. ...
3. ...
---
"""
)

quiz_generation_prompt = PromptTemplate(
    input_variables=["content", "num_questions", "difficulty"],
    template="""
ë‹¤ìŒ êµì¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {num_questions}ê°œì˜ ê°ê´€ì‹ 4ì§€ì„ ë‹¤ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.
ì¶œë ¥ í˜•ì‹ì€ **JSON ë°°ì—´**ë¡œ ë°˜ë“œì‹œ ë‹¤ìŒ êµ¬ì¡°ë¥¼ ì§€ì¼œì•¼ í•©ë‹ˆë‹¤.

[
  {{
    "question": "ë¬¸ì œ ë‚´ìš©",
    "options": {{
      "a": "ë³´ê¸° a",
      "b": "ë³´ê¸° b",
      "c": "ë³´ê¸° c",
      "d": "ë³´ê¸° d"
    }}
  }},
  ...
]

- ë‚œì´ë„ëŠ” {difficulty} ì…ë‹ˆë‹¤.
- ê° ë¬¸ì œëŠ” í•˜ë‚˜ì˜ ëª…í™•í•œ ì •ë‹µì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.
- ì •ë‹µ í‘œì‹œë‚˜ 'ì •ë‹µ:' ë“±ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- ì¤‘ë³µ ë¬¸ì œ ê¸ˆì§€

ë‚´ìš©:
{content}
"""
)

grading_prompt = PromptTemplate(
    input_variables=["question", "user_answer", "context"],
    template="""
ë‹¹ì‹ ì€ ì£¼ì–´ì§„ 'êµì¬ ë‚´ìš©'ì—ë§Œ ê·¼ê±°í•˜ì—¬ í€´ì¦ˆë¥¼ ì±„ì í•˜ëŠ” AI ì¡°êµì…ë‹ˆë‹¤. ì™¸ë¶€ ì§€ì‹ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

**[ì±„ì  ì ˆì°¨]**
1. **ì •ë‹µ ì°¾ê¸°**: 'êµì¬ ë‚´ìš©'ì—ì„œ 'ë¬¸ì œ'ì— ëŒ€í•œ ëª…í™•í•œ ì •ë‹µì„ ì°¾ìŠµë‹ˆë‹¤.
2. **ë‹µë³€ ë¹„êµ**: 'ì‚¬ìš©ì ë‹µë³€'ì„ ì •ë‹µê³¼ ë¹„êµí•©ë‹ˆë‹¤.
   - ê°ê´€ì‹ ë¬¸ì œ: **ì‚¬ìš©ì ë‹µë³€ì´ 'b) í‚¤ êµí™˜' í˜•íƒœì´ê±°ë‚˜ ë‹¨ìˆœíˆ 'b' ë˜ëŠ” 'b)'ì™€ ê°™ì´ ì •ë‹µ ì„ íƒì§€ ë²ˆí˜¸ë§Œ í¬í•¨í•˜ëŠ” ê²½ìš° ëª¨ë‘ ì •ë‹µìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.**
3. **ì¶œë ¥ í˜•ì‹ ì¤€ìˆ˜**: ì±„ì  ê²°ê³¼ë¥¼ ì•„ë˜ 'ì¶œë ¥ í˜•ì‹'ì— ë§ì¶° ì •í™•í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤.

---
**êµì¬ ë‚´ìš© (Source of Truth):**
{context}
---
**ë¬¸ì œ:**
{question}
---
**ì‚¬ìš©ì ë‹µë³€:**
{user_answer}
---
**[ì±„ì  ê²°ê³¼ ì¶œë ¥]**
ì •ë‹µì—¬ë¶€: [ì •ë‹µ/ì˜¤ë‹µ]
ì •ë‹µ: [êµì¬ ë‚´ìš©ì— ê·¼ê±°í•œ ëª…í™•í•˜ê³  ê°„ê²°í•œ ì •ë‹µì„ ì—¬ê¸°ì— ì„œìˆ  (ì˜ˆ: b) í‚¤ êµí™˜)]
ì„¤ëª…: [ì‚¬ìš©ì ë‹µë³€ì´ ì •ë‹µì¸ ì´ìœ , ë˜ëŠ” ì˜¤ë‹µì¸ ê²½ìš° ì •í™•í•œ ì„¤ëª…]
"""
)

def summarize_pdf_content(content: str) -> str:
    """ì „ì²´ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤."""
    prompt = summary_prompt.format(content=content[:10000]) # 4000ìì—ì„œ 10000ìë¡œ í™•ì¥
    result = llm.invoke(prompt)
    return result.content.strip()

def summarize_subchapters(content: str, request_chapter: Optional[str] = None) -> Tuple[List[Dict[str, str]], str]:
    """ë‹¨ì›ë³„ ìš”ì•½ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    chapters = split_by_subchapter(content)
    if not chapters:
        return [], "âŒ ë¬¸ì„œì—ì„œ ì†Œë‹¨ì›(ì˜ˆ: 4.1)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    summaries = []
    
    # 1. íŠ¹ì • ë‹¨ì› ìš”ì²­ (ì˜ˆ: '4.1ì¥' ë˜ëŠ” '4ì¥')
    if request_chapter:
        req = request_chapter.strip().lower()
        matched_keys = []
        
        # ìˆ«ì.ìˆ«ì íŒ¨í„´ ìš°ì„ 
        m_dot = re.search(r"(\d+\.\d+)", req)
        if m_dot:
            key = m_dot.group(1)
            if key in chapters:
                matched_keys.append(key)
        
        # ìˆ«ì íŒ¨í„´ (ìƒìœ„ ì¥)
        m_major = re.search(r"(\d+)", req)
        if not matched_keys and m_major:
            major = m_major.group(1) 
            matched_keys = sorted([k for k in chapters.keys() if k.startswith(f"{major}.")])
            
        if not matched_keys:
            return [], f"âŒ ìš”ì²­í•œ ë‹¨ì› '{request_chapter}' ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ë§¤ì¹­ëœ ë‹¨ì›ë“¤ë§Œ ê²°í•© ë° ìš”ì•½
        combined = "\n\n".join([chapters[k] for k in matched_keys])
        summary = summarize_pdf_content(combined)
        summaries.append({"chapter": ", ".join(matched_keys), "summaryText": summary})
        
        return summaries, "âœ… ìš”ì²­ëœ ë‹¨ì› ìš”ì•½ ì™„ë£Œ"

    # 2. ì „ì²´ ë‹¨ì› ìš”ì•½ ìš”ì²­ (request_chapterê°€ Noneì¼ ë•Œ)
    for key, text in chapters.items():
        summary = summarize_pdf_content(text)
        summaries.append({"chapter": key, "summaryText": summary})
        
    return summaries, "âœ… ë‹¨ì›ë³„ ì „ì²´ ìš”ì•½ ì™„ë£Œ"


# ===============================================
# ====== FastAPI Endpoints ======
# ===============================================

@app.get("/health/")
async def health_check():
    return {"status": "ok"}

@app.post("/upload_pdfs/")
async def upload_pdfs(files: List[UploadFile] = File(...)):
    saved_files = []
    for file in files:
        save_path = os.path.join(UPLOAD_DIR, file.filename)
        try:
            with open(save_path, "wb") as f:
                f.write(await file.read())
            saved_files.append(save_path)
        except Exception as e:
            return {"error": str(e)}
    return {"saved_files": saved_files}

@app.post("/summarize/full")
async def summarize_full(request: PdfPathsRequest):
    _, content = combine_vectorstores(request.pdf_paths)
    if not content:
        raise HTTPException(status_code=400, detail="PDF ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨")
    prompt = f"ë‹¤ìŒ ë‚´ìš©ì„ í•µì‹¬ ìš”ì•½: {content[:10000]}"
    result = llm.invoke(prompt)
    return {"summaryText": result.content.strip()}

@app.post("/summarize/chapter")
async def summarize_chapter(request: ChapterRequest):
    _, content = combine_vectorstores(request.pdf_paths)
    
    if not content:
        raise HTTPException(status_code=400, detail="PDF ë‚´ìš©ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    summaries, message = summarize_subchapters(content, request_chapter=request.chapter_request)
    
    if not summaries:
         raise HTTPException(status_code=404, detail=message)
         
    return {"message": message, "summaries": summaries}

# -----------------------------------------------
# ì§ˆë¬¸ ë‹µë³€ ì—”ë“œí¬ì¸íŠ¸
# -----------------------------------------------

@app.post("/question/")
async def question_endpoint(request: QuestionRequest):
    """ì§ˆë¬¸ ë‹µë³€ (RAG + Web Search Fallback)."""
    question = request.question
    vectorstore, _ = combine_vectorstores(request.pdf_paths)
    
    if not vectorstore:
        raise HTTPException(status_code=400, detail="PDF ë²¡í„° ë¡œë“œ ì‹¤íŒ¨. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
    # 1. RAG ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
    docs = vectorstore.similarity_search(question, k=4)
    vector_context = "\n".join([d.page_content for d in docs])
    
    web_context = ""
    
    # 2. ë²¡í„° ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡± ì‹œ (ë¬¸ì„œ 1ê°œ ë¯¸ë§Œ), Tavily ì›¹ ê²€ìƒ‰ ì‹œë„
    if not vector_context or len(vector_context.strip()) < 100:
        logger.info("ğŸ“¡ PDFì—ì„œ ì¶©ë¶„í•œ ë‹µì„ ì°¾ì§€ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰")
        try:
            if tavily_tool:
                tavily_results = tavily_tool.run(question)
                if tavily_results:
                    web_context += "\n\n--- ì›¹ ê²€ìƒ‰ ê²°ê³¼ (Tavily) ---\n\n"
                    for item in tavily_results:
                        web_context += f"ì¶œì²˜: {item.get('url','N/A')}\në‚´ìš©: {item.get('content', item.get('snippet',''))}\n\n"
            else:
                logger.warning("âš ï¸ Tavily API Key ì—†ìŒ â†’ DuckDuckGo ëŒ€ì²´ ê²€ìƒ‰")
                duck = DuckDuckGoSearchRun()
                search_text = duck.run(question)
                web_context += f"\n\n--- ì›¹ ê²€ìƒ‰ ê²°ê³¼ (DuckDuckGo) ---\n\n{search_text}\n"
        except Exception as e:
            logger.error(f"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            web_context = ""

    # 3. ë‹µë³€ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    final_context = f"--- êµì¬(PDF) ë‚´ìš© ---\n{vector_context}\n{web_context}"
    
    prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì œê³µí•œ êµì¬ ë‚´ìš©ê³¼ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. 

    - êµì¬ ë‚´ìš©(PDF)ì´ ìˆë‹¤ë©´ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
    - êµì¬ ë‚´ìš©ë§Œìœ¼ë¡œ ë‹µë³€ì´ ì–´ë µê±°ë‚˜, êµì¬ ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
    - ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í–ˆì„ ê²½ìš°, ë‹µë³€ ë§ë¯¸ì— 'ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì°¸ê³ ë˜ì—ˆìŠµë‹ˆë‹¤.'ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.
    
    ì œê³µëœ ëª¨ë“  ì»¨í…ìŠ¤íŠ¸:
    {final_context}
    
    ì§ˆë¬¸: {question}
    
    ë‹µë³€:"""
    
    # 4. LLM í˜¸ì¶œ
    result = llm.invoke(prompt)
    answer = result.content.strip()
    return {"answer": answer}

# -----------------------------------------------
# ì—°ìŠµë¬¸ì œ ì—”ë“œí¬ì¸íŠ¸
# -----------------------------------------------

@app.post("/quiz/generate")
async def quiz_generate(request: QuizGenerationRequest):
    _, content = combine_vectorstores(request.pdf_paths)
    if not content:
        raise HTTPException(status_code=400, detail="PDF ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨")
    prompt = f"ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {request.num_questions}ê°œ ê°ê´€ì‹ ë¬¸ì œ ìƒì„±, ë‚œì´ë„ {request.difficulty}: {content[:10000]}"
    result = llm.invoke(prompt)
    try:
        questions = json.loads(result.content.strip())
    except:
        questions = [{"question": result.content.strip()}]
    return {"questions": questions}

@app.post("/quiz/grade")
async def quiz_grade(request: QuizGradingRequest):
    """ì‚¬ìš©ìì˜ ë‹µë³€ì„ ì±„ì í•˜ê³  ê²°ê³¼ì™€ ì„¤ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    _, content = combine_vectorstores(request.pdf_paths)
    
    if not content:
        raise HTTPException(status_code=400, detail="PDF ë‚´ìš©ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    results = []
    total_score = 0
    correct_count = 0
    num_total_questions = len(request.answers)
    score_per_question = 100 // num_total_questions if num_total_questions > 0 else 0
    
    for ans in request.answers:
        grade_prompt_text = grading_prompt.format(
            question=ans.question_text,
            user_answer=ans.user_answer,
            context=content[:10000]
        )

        try:
            result = llm.invoke(grade_prompt_text)
            result_text = result.content.strip()

            # LLM ì‘ë‹µì—ì„œ ë°ì´í„° ì¶”ì¶œ
            is_correct_str_match = re.search(r"ì •ë‹µì—¬ë¶€:\s*([^\n]+)", result_text)
            correct_answer_match = re.search(r"ì •ë‹µ:\s*([^\n]+)", result_text, re.DOTALL)
            explanation_match = re.search(r"ì„¤ëª…:\s*([^\n]+)", result_text, re.DOTALL)

            is_correct = "ì •ë‹µ" in is_correct_str_match.group(1).strip() if is_correct_str_match else False
            correct_answer = correct_answer_match.group(1).strip() if correct_answer_match else "ì±„ì  ì˜¤ë¥˜: ì •ë‹µ ë¯¸í¬í•¨"
            explanation = explanation_match.group(1).strip() if explanation_match else "ì±„ì  ì˜¤ë¥˜: ì„¤ëª… ë¯¸í¬í•¨"

            score = score_per_question if is_correct else 0
            total_score += score
            if is_correct:
                correct_count += 1
            
            results.append({
                "question": ans.question_text,
                "user_answer": ans.user_answer,
                "correct_answer": correct_answer,
                "explanation": explanation,
                "is_correct": is_correct,
                "score": score
            })

        except Exception as e:
            logger.error(f"ì±„ì  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            results.append({
                "question": ans.question_text,
                "user_answer": ans.user_answer,
                "correct_answer": "ì‹œìŠ¤í…œ ì˜¤ë¥˜",
                "explanation": f"ì±„ì  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}",
                "is_correct": False,
                "score": 0
            })
            
    # ìµœì¢… ì ìˆ˜ ë³´ì • (100ì  ë§Œì ìœ¼ë¡œ)
    final_total_score = total_score
    remaining_score = 100 - (score_per_question * num_total_questions)
    
    if remaining_score > 0 and correct_count > 0:
        for res in reversed(results):
            if res['is_correct']:
                res['score'] += remaining_score
                final_total_score += remaining_score
                break
    
    if correct_count == 0:
        final_total_score = 0

    return {
        "final_total_score": final_total_score,
        "correct_count": correct_count,
        "total_questions": num_total_questions,
        "results": results
    }