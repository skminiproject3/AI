import os
import re
import hashlib
import json
from typing import List, Tuple, Optional, Dict, Any
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Depends
from fastapi.responses import JSONResponse
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain.prompts import PromptTemplate
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_community.vectorstores import FAISS
from pydantic import BaseModel, Field
import logging
from typing import List, Optional
# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# ì—…ë¡œë“œ í´ë” ì •ì˜
UPLOAD_DIR = "uploaded_pdfs"
os.makedirs(UPLOAD_DIR, exist_ok=True)  # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±

# ====== Pydantic ëª¨ë¸ ì •ì˜ ======
class PdfPathsRequest(BaseModel):
    pdf_paths: List[str]
class ChapterRequest(BaseModel):
    pdf_paths: List[str]
    chapter_request: Optional[str] = None
class QuestionRequest(BaseModel):
    question: str
    pdf_paths: List[str]

class QuizGenerationRequest(BaseModel):
    pdf_paths: List[str]
    num_questions: int = Field(5, ge=1, le=20)
    difficulty: str = Field("MEDIUM", pattern="^(EASY|MEDIUM|HARD)$")

class QuizAnswer(BaseModel):
    question_text: str  # ì§ˆë¬¸ ì›ë¬¸
    user_answer: str    # ì‚¬ìš©ì ë‹µë³€

class QuizGradingRequest(BaseModel):
    pdf_paths: List[str]
    answers: List[QuizAnswer]
    # score_per_question: int = Field(20) # ë°±ì—”ë“œì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ì œê±°

# ====== í™˜ê²½ ì„¤ì • ======
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2, api_key=OPENAI_API_KEY)
embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)

# Tavily ë„êµ¬ ì´ˆê¸°í™” (API Keyê°€ ì—†ìœ¼ë©´ None)
tavily_tool = TavilySearchResults(api_key=TAVILY_API_KEY, max_results=3) if TAVILY_API_KEY else None

app = FastAPI(title="PDF í•™ìŠµ ë„ìš°ë¯¸ API")

# ===============================================
# ====== Core Functions (PDF/Vector/Text Processing) ======
# ===============================================

def extract_text_from_pdf(pdf_path: str) -> str:
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        loader = PyPDFLoader(pdf_path)
        pages = loader.load()
        return "\n".join([p.page_content for p in pages])
    except Exception as e:
        logger.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ({pdf_path}): {e}")
        return ""

def get_or_create_vectorstore(pdf_path: str) -> Optional[FAISS]:
    """PDF ê²½ë¡œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤."""
    base_vector_dir = "vector_stores"
    normalized_path = pdf_path.replace('\\', '/')
    path_hash = hashlib.md5(normalized_path.encode()).hexdigest()
    vector_path = os.path.join(base_vector_dir, path_hash)

    if not os.path.exists(base_vector_dir):
        os.makedirs(base_vector_dir)

    if os.path.exists(vector_path):
        return FAISS.load_local(vector_path, embeddings, allow_dangerous_deserialization=True)
    else:
        logger.info(f"ğŸ”„ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹œì‘: {pdf_path}")
        try:
            loader = PyPDFLoader(pdf_path)
            pages = loader.load()
            texts = [p.page_content for p in pages]
            if not texts:
                logger.warning(f"ê²½ê³ : {pdf_path}ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return None
            vectorstore = FAISS.from_texts(texts, embeddings)
            vectorstore.save_local(vector_path)
            logger.info(f"âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥ ì™„ë£Œ: {pdf_path}")
            return vectorstore
        except Exception as e:
            logger.error(f"âŒ ë²¡í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({pdf_path}): {e}")
            return None

def combine_vectorstores(pdf_paths: List[str]) -> Tuple[Optional[FAISS], Optional[str]]:
    vectorstores = []
    combined_content = ""
    
    for pdf_path in pdf_paths:
        if not os.path.exists(pdf_path):
            continue

        vs = get_or_create_vectorstore(pdf_path)
        if vs:
            vectorstores.append(vs)
            combined_content += extract_text_from_pdf(pdf_path) + "\n\n--- PDF ë¶„ë¦¬ ---\n\n"

    if not vectorstores:
        return None, None

    main_vs = vectorstores[0]
    for i in range(1, len(vectorstores)):
        main_vs.merge_from(vectorstores[i])

    return main_vs, combined_content.strip()


def split_by_subchapter(text: str) -> Dict[str, str]:
    """í…ìŠ¤íŠ¸ì—ì„œ 'ìˆ«ì.ìˆ«ì' ë˜ëŠ” 'ìˆ«ì.ìˆ«ì.ìˆ«ì' í˜•íƒœë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤."""
    # (ìˆ«ì.ìˆ«ì) ë˜ëŠ” (ìˆ«ì.ìˆ«ì.ìˆ«ì) í˜•íƒœë¥¼ ì¸ì‹í•˜ë„ë¡ ì •ê·œí‘œí˜„ì‹ í™•ì¥
    pattern = r"(?=(\d+\.\d+(\.\d+)?))"
    splits = re.split(pattern, text)
    chapters = {}
    current_chapter = None
    
    # re.split()ì€ ê·¸ë£¹ì„ í¬í•¨í•˜ë¯€ë¡œ, ê·¸ë£¹ë„ ê²°ê³¼ì— í¬í•¨ë¨.
    # ë”°ë¼ì„œ, ìº¡ì²˜ëœ ê·¸ë£¹ì„ ê±´ë„ˆë›°ê³  í…ìŠ¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì²˜ë¦¬í•´ì•¼ í•¨.
    for seg in splits:
        if seg is None or not seg.strip():
             continue
             
        # ìˆ«ìë¡œ ì‹œì‘í•˜ê³  ì ì„ í¬í•¨í•˜ëŠ” ì±•í„° í‚¤ ë§¤ì¹­ (ì˜ˆ: 4.1, 4.1.1)
        if re.match(r"^\d+\.\d+(\.\d+)?$", seg.strip()):
            current_chapter = seg.strip()
            chapters[current_chapter] = ""
        elif current_chapter:
            chapters[current_chapter] += seg.strip() + "\n"
            
    return chapters

# ===============================================
# ====== LLM Prompts and Functions (Summary & Quiz) ======
# ===============================================

summary_prompt = PromptTemplate(
    input_variables=["content"],
    template="""
ë‹¹ì‹ ì€ êµì¬ì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë‚´ìš©ì„ í•µì‹¬ ê°œë… ì¤‘ì‹¬ìœ¼ë¡œ ê°„ê²°í•˜ê³  ëª…ë£Œí•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”.

- ì£¼ìš” ê°œë… 3~5ê°œ ì¤‘ì‹¬
- ê³µì‹, ì •ì˜, íŠ¹ì§• í¬í•¨

ë‚´ìš©:
{content}

ì¶œë ¥ í˜•ì‹:
---
[ìš”ì•½]
1. ...
2. ...
3. ...
---
"""
)

bulk_summary_prompt = PromptTemplate(
    input_variables=["content", "chapters_list"],
    template="""
ë‹¹ì‹ ì€ êµì¬ì˜ í•µì‹¬ ë‚´ìš©ì„ ë‹¨ì›ë³„ë¡œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì•„ë˜ ì§€ì •ëœ ì†Œë‹¨ì› ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ ê°ê° í•µì‹¬ ìš”ì•½(3~5ê°œ í•­ëª©)ì„ ì‘ì„±í•˜ì„¸ìš”.

- ìš”ì•½ì€ ê°„ê²°í•˜ê³  ëª…ë£Œí•´ì•¼ í•˜ë©°, ì£¼ìš” ê°œë…ê³¼ ì •ì˜ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
- ì‘ë‹µì€ **ë°˜ë“œì‹œ** ë‹¤ìŒì˜ **JSON ë°°ì—´** í˜•ì‹ìœ¼ë¡œë§Œ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- chapters_listì˜ ë‹¨ì› ë²ˆí˜¸ì™€ ì •í™•íˆ ì¼ì¹˜ì‹œì¼œ JSONì˜ "chapter" í•„ë“œì— ê°’ì„ ë„£ìœ¼ì„¸ìš”.

ë‚´ìš©:
{content}

---
ìš”ì•½í•  ì†Œë‹¨ì› ë¦¬ìŠ¤íŠ¸: {chapters_list}

ì¶œë ¥ í˜•ì‹:
[
  {{
    "chapter": "ë‹¨ì› ë²ˆí˜¸ (ì˜ˆ: 4.1)",
    "summaryText": "--- \n[ìš”ì•½]\n1. ...\n2. ...\n3. ...\n---" 
  }},
  // ... ëª¨ë“  ì†Œë‹¨ì›ì— ëŒ€í•´ ë°˜ë³µ
]
"""
)

quiz_generation_prompt = PromptTemplate(
    input_variables=["content", "num_questions", "difficulty"],
    template="""
ë‹¤ìŒ êµì¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {num_questions}ê°œì˜ ê°ê´€ì‹ 4ì§€ì„ ë‹¤ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.
ì¶œë ¥ í˜•ì‹ì€ **JSON ë°°ì—´**ë¡œ ë°˜ë“œì‹œ ë‹¤ìŒ êµ¬ì¡°ë¥¼ ì§€ì¼œì•¼ í•©ë‹ˆë‹¤.

[
  {{
    "question": "ë¬¸ì œ ë‚´ìš©",
    "options": {{
      "a": "ë³´ê¸° a",
      "b": "ë³´ê¸° b",
      "c": "ë³´ê¸° c",
      "d": "ë³´ê¸° d"
    }}
  }},
  ...
]

- ë‚œì´ë„ëŠ” {difficulty} ì…ë‹ˆë‹¤.
- ê° ë¬¸ì œëŠ” í•˜ë‚˜ì˜ ëª…í™•í•œ ì •ë‹µì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.
- ì •ë‹µ í‘œì‹œë‚˜ 'ì •ë‹µ:' ë“±ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- ì¤‘ë³µ ë¬¸ì œ ê¸ˆì§€

ë‚´ìš©:
{content}
"""
)

grading_prompt = PromptTemplate(
    input_variables=["question", "user_answer", "context"],
    template="""
ë‹¹ì‹ ì€ ì£¼ì–´ì§„ 'êµì¬ ë‚´ìš©'ì—ë§Œ ê·¼ê±°í•˜ì—¬ í€´ì¦ˆë¥¼ ì±„ì í•˜ëŠ” AI ì¡°êµì…ë‹ˆë‹¤. ì™¸ë¶€ ì§€ì‹ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

**[ì±„ì  ì ˆì°¨]**
1. **ì •ë‹µ ì°¾ê¸°**: 'êµì¬ ë‚´ìš©'ì—ì„œ 'ë¬¸ì œ'ì— ëŒ€í•œ ëª…í™•í•œ ì •ë‹µì„ ì°¾ìŠµë‹ˆë‹¤.
2. **ë‹µë³€ ë¹„êµ**: 'ì‚¬ìš©ì ë‹µë³€'ì„ ì •ë‹µê³¼ ë¹„êµí•©ë‹ˆë‹¤.
   - ê°ê´€ì‹ ë¬¸ì œ: **ì‚¬ìš©ì ë‹µë³€ì´ 'b) í‚¤ êµí™˜' í˜•íƒœì´ê±°ë‚˜ ë‹¨ìˆœíˆ 'b' ë˜ëŠ” 'b)'ì™€ ê°™ì´ ì •ë‹µ ì„ íƒì§€ ë²ˆí˜¸ë§Œ í¬í•¨í•˜ëŠ” ê²½ìš° ëª¨ë‘ ì •ë‹µìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.**
3. **ì¶œë ¥ í˜•ì‹ ì¤€ìˆ˜**: ì±„ì  ê²°ê³¼ë¥¼ ì•„ë˜ 'ì¶œë ¥ í˜•ì‹'ì— ë§ì¶° ì •í™•í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤.

---
**êµì¬ ë‚´ìš© (Source of Truth):**
{context}
---
**ë¬¸ì œ:**
{question}
---
**ì‚¬ìš©ì ë‹µë³€:**
{user_answer}
---
**[ì±„ì  ê²°ê³¼ ì¶œë ¥]**
ì •ë‹µì—¬ë¶€: [ì •ë‹µ/ì˜¤ë‹µ]
ì •ë‹µ: [êµì¬ ë‚´ìš©ì— ê·¼ê±°í•œ ëª…í™•í•˜ê³  ê°„ê²°í•œ ì •ë‹µì„ ì—¬ê¸°ì— ì„œìˆ  (ì˜ˆ: b) í‚¤ êµí™˜)]
ì„¤ëª…: [ì‚¬ìš©ì ë‹µë³€ì´ ì •ë‹µì¸ ì´ìœ , ë˜ëŠ” ì˜¤ë‹µì¸ ê²½ìš° ì •í™•í•œ ì„¤ëª…]
"""
)

def summarize_pdf_content(content: str) -> str:
    """ì „ì²´ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤."""
    prompt = summary_prompt.format(content=content[:10000]) # 4000ìì—ì„œ 10000ìë¡œ í™•ì¥
    result = llm.invoke(prompt)
    return result.content.strip()

def summarize_subchapters(content: str, request_chapter: Optional[str] = None) -> Tuple[List[Dict[str, str]], str]:
    """ë‹¨ì›ë³„ ìš”ì•½ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    chapters = split_by_subchapter(content)
    if not chapters:
        return [], "âŒ ë¬¸ì„œì—ì„œ ì†Œë‹¨ì›(ì˜ˆ: 4.1)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    summaries = []
    
    # 1. íŠ¹ì • ë‹¨ì› ìš”ì²­ ì²˜ë¦¬ ë¡œì§ (Case 1)
    if request_chapter and request_chapter.strip(): # ğŸ‘ˆ None ë˜ëŠ” ë¹ˆ ë¬¸ìì—´ ê²€ì‚¬ ì¶”ê°€
        logger.info(f"â¡ï¸ íŠ¹ì • ë‹¨ì› ìš”ì²­ ê°ì§€: {request_chapter}")
        
        match = re.search(r"(\d+\.\d+)", request_chapter)
        if not match:
            logger.warning(f"âŒ ìš”ì²­ì—ì„œ ìœ íš¨í•œ ë‹¨ì› ë²ˆí˜¸(ì˜ˆ: 4.2)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {request_chapter}")
            # ìœ íš¨í•œ ë‹¨ì› ë²ˆí˜¸ê°€ ì—†ì–´ë„ ì „ì²´ ìš”ì•½ì„ ì‹œí‚¤ì§€ ì•Šê³  ì˜¤ë¥˜ ì²˜ë¦¬
            return [], f"âŒ ìš”ì²­ì—ì„œ ìœ íš¨í•œ ë‹¨ì› ë²ˆí˜¸(ì˜ˆ: 4.2)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {request_chapter}"
        
        target_chapter = match.group(1)
        matched_keys = sorted([k for k in chapters.keys() if k.startswith(target_chapter)])
        
        if not matched_keys:
            return [], f"âŒ ì»¨í…ì¸ ì—ì„œ ìš”ì²­í•˜ì‹  ë‹¨ì›({target_chapter})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ë‹¨ì›: {', '.join(sorted(chapters.keys()))[:100]}..."
        
        combined = "\n\n".join([chapters[k] for k in matched_keys if k in chapters])
        summary = summarize_pdf_content(combined) 
        
        summaries.append({"chapter": ", ".join(matched_keys), "summaryText": summary})
        
        logger.info(f"âœ… ë‹¨ì› ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ: {target_chapter}")
        return summaries, f"âœ… ìš”ì²­ëœ ë‹¨ì› ({target_chapter}) ìš”ì•½ ì™„ë£Œ"
        
    # 2. ì „ì²´ ë‹¨ì› ìš”ì•½ ìš”ì²­ (Case 2: request_chapterê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš°)
    logger.info("â¡ï¸ ì „ì²´ ë‹¨ì› ìš”ì•½ ìš”ì²­ìœ¼ë¡œ ì „í™˜ë©ë‹ˆë‹¤ (request_chapter ì—†ìŒ ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•ŠìŒ).")
    
    all_chapters_keys = sorted(chapters.keys())
    
    bulk_prompt = bulk_summary_prompt.format(
        content=content[:10000], # ìµœëŒ€ 10000ì ì‚¬ìš©
        chapters_list=all_chapters_keys
    )
    
    try:
        result = llm.invoke(bulk_prompt)
        
        raw_json_text = result.content.strip()
        # LLMì´ JSON ì‘ë‹µì— ë§ˆí¬ë‹¤ìš´ì„ ë¶™ì´ëŠ” ê²½ìš° ì œê±°
        if raw_json_text.startswith("```json"):
            raw_json_text = raw_json_text[7:]
        if raw_json_text.endswith("```"):
            raw_json_text = raw_json_text[:-3]

        # ğŸ’¡ í•µì‹¬ ê°œì„ : JSONDecodeError ë°©ì§€ìš© ì œì–´ ë¬¸ì ì œê±°
        # \x00-\x08 (NULL, backspace, etc.) \x0b, \x0c, \x0e-\x1f (vertical tab, form feed, etc.) \x7f-\x9f (DEL, C1 control codes)
        # \n, \r, \tëŠ” JSONì—ì„œ í—ˆìš©ë˜ê±°ë‚˜ \në¡œ ì´ìŠ¤ì¼€ì´í”„ë˜ë¯€ë¡œ ì œì™¸í•©ë‹ˆë‹¤.
        cleaned_json_text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]', '', raw_json_text) 

        summaries_list = json.loads(cleaned_json_text) # ğŸ‘ˆ ì •ì œëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
        
        # ê²°ê³¼ í•„í„°ë§ ë° í˜•ì‹ í™•ì¸
        for item in summaries_list:
            if 'chapter' in item and 'summaryText' in item:
                summaries.append({"chapter": item['chapter'], "summaryText": item['summaryText']})
        
        if not summaries:
            return [], "âŒ LLMì´ ìœ íš¨í•œ JSON í˜•ì‹ì˜ ìš”ì•½ ëª©ë¡ì„ ë°˜í™˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    except json.JSONDecodeError as e:
        logger.error(f"âŒ LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ (JSONDecodeError): {e} \n ì›ë³¸ ì‘ë‹µ ì‹œì‘: {raw_json_text[:100]}...")
        return [], "âŒ LLMì´ ìš”ì²­ëœ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”."
    except Exception as e:
        logger.error(f"âŒ ì „ì²´ ìš”ì•½ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return [], f"âŒ ì „ì²´ ìš”ì•½ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        
    return summaries, "âœ… ë‹¨ì›ë³„ ì¼ê´„ ìš”ì•½ ì™„ë£Œ (LLM 1íšŒ í˜¸ì¶œ)"


# ===============================================
# ====== FastAPI Endpoints ======
# ===============================================

@app.get("/health/")
async def health_check():
    return {"status": "ok"}

@app.post("/upload_pdfs/")
async def upload_pdfs(files: List[UploadFile] = File(...)):
    saved_files = []
    created_vectors = []
    
    for file in files:
        save_path = os.path.join(UPLOAD_DIR, file.filename)
        
        # 1. íŒŒì¼ ì €ì¥
        try:
            with open(save_path, "wb") as f:
                f.write(await file.read())
            saved_files.append(save_path)
            
            # 2. íŒŒì¼ ì €ì¥ ì§í›„ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥ ì‹œë„ (ì¶”ê°€ëœ ë¶€ë¶„)
            logger.info(f"âœ¨ ì—…ë¡œë“œ ì§í›„ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤: {save_path}")
            vs = get_or_create_vectorstore(save_path)
            
            if vs:
                created_vectors.append(save_path)
            else:
                logger.error(f"âŒ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {save_path}")

        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ì—…ë¡œë“œ ë˜ëŠ” ë²¡í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì´ì „ì— ì €ì¥ëœ íŒŒì¼ì´ ìˆë‹¤ë©´ ì •ë¦¬í•  ìˆ˜ë„ ìˆì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì˜¤ë¥˜ ì‘ë‹µ
            return JSONResponse(status_code=500, content={"error": f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"})
            
    return {
        "saved_files": saved_files,
        "vector_status": f"{len(created_vectors)}ê°œì˜ íŒŒì¼ì— ëŒ€í•œ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ.",
        "created_vectors_for": created_vectors
    }

@app.post("/summarize/full")
async def summarize_full(request: PdfPathsRequest):
    _, content = combine_vectorstores(request.pdf_paths)
    if not content:
        raise HTTPException(status_code=400, detail="PDF ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨")
    prompt = f"ë‹¤ìŒ ë‚´ìš©ì„ í•µì‹¬ ìš”ì•½: {content[:10000]}"
    result = llm.invoke(prompt)
    return {"summaryText": result.content.strip()}

@app.post("/summarize/chapter")
async def summarize_chapter(request: ChapterRequest): # ğŸ‘ˆ ChapterRequest ëª¨ë¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    """ë‹¨ì›ë³„ ìš”ì•½ (ì „ì²´ ë˜ëŠ” íŠ¹ì • ë‹¨ì› ìš”ì²­)."""
    
    _, content = combine_vectorstores(request.pdf_paths) 
    
    if not content:
        raise HTTPException(status_code=400, detail="PDF ë‚´ìš©ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    # request.chapter_requestëŠ” "4.2ì¥ë§Œ ìš”ì•½í•´ì¤˜" ê°™ì€ ìš”ì²­ ë¬¸ìì—´ì´ê±°ë‚˜ Noneì…ë‹ˆë‹¤.
    summaries, message = summarize_subchapters(content, request_chapter=request.chapter_request)
    
    if not summaries:
        # LLM ì‘ë‹µ ì‹¤íŒ¨ë‚˜ PDF ë‚´ìš© ë¡œë“œ ì‹¤íŒ¨ ì‹œ 404/400 ëŒ€ì‹  ì—¬ê¸°ì„œ 404 ë°˜í™˜
        raise HTTPException(status_code=404, detail=message)
        
    return {"message": message, "summaries": summaries}

# -----------------------------------------------
# ì§ˆë¬¸ ë‹µë³€ ì—”ë“œí¬ì¸íŠ¸
# -----------------------------------------------

@app.post("/question/")
async def question_endpoint(request: QuestionRequest):
    """ì§ˆë¬¸ ë‹µë³€ (RAG + Web Search Fallback)."""
    question = request.question
    vectorstore, _ = combine_vectorstores(request.pdf_paths)
    
    if not vectorstore:
        raise HTTPException(status_code=400, detail="PDF ë²¡í„° ë¡œë“œ ì‹¤íŒ¨. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
    # 1. RAG ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
    docs = vectorstore.similarity_search(question, k=4)
    vector_context = "\n".join([d.page_content for d in docs])
    
    web_context = ""
    
    # 2. ë²¡í„° ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡± ì‹œ (ë¬¸ì„œ 1ê°œ ë¯¸ë§Œ), Tavily ì›¹ ê²€ìƒ‰ ì‹œë„
    if not vector_context or len(vector_context.strip()) < 100:
        logger.info("ğŸ“¡ PDFì—ì„œ ì¶©ë¶„í•œ ë‹µì„ ì°¾ì§€ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰")
        try:
            if tavily_tool:
                tavily_results = tavily_tool.run(question)
                if tavily_results:
                    web_context += "\n\n--- ì›¹ ê²€ìƒ‰ ê²°ê³¼ (Tavily) ---\n\n"
                    for item in tavily_results:
                        web_context += f"ì¶œì²˜: {item.get('url','N/A')}\në‚´ìš©: {item.get('content', item.get('snippet',''))}\n\n"
            else:
                logger.warning("âš ï¸ Tavily API Key ì—†ìŒ â†’ DuckDuckGo ëŒ€ì²´ ê²€ìƒ‰")
                duck = DuckDuckGoSearchRun()
                search_text = duck.run(question)
                web_context += f"\n\n--- ì›¹ ê²€ìƒ‰ ê²°ê³¼ (DuckDuckGo) ---\n\n{search_text}\n"
        except Exception as e:
            logger.error(f"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            web_context = ""

    # 3. ë‹µë³€ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    final_context = f"--- êµì¬(PDF) ë‚´ìš© ---\n{vector_context}\n{web_context}"
    
    prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì œê³µí•œ êµì¬ ë‚´ìš©ê³¼ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. 

    - êµì¬ ë‚´ìš©(PDF)ì´ ìˆë‹¤ë©´ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
    - êµì¬ ë‚´ìš©ë§Œìœ¼ë¡œ ë‹µë³€ì´ ì–´ë µê±°ë‚˜, êµì¬ ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
    - ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í–ˆì„ ê²½ìš°, ë‹µë³€ ë§ë¯¸ì— 'ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì°¸ê³ ë˜ì—ˆìŠµë‹ˆë‹¤.'ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.
    
    ì œê³µëœ ëª¨ë“  ì»¨í…ìŠ¤íŠ¸:
    {final_context}
    
    ì§ˆë¬¸: {question}
    
    ë‹µë³€:"""
    
    # 4. LLM í˜¸ì¶œ
    result = llm.invoke(prompt)
    answer = result.content.strip()
    return {"answer": answer}

# -----------------------------------------------
# ì—°ìŠµë¬¸ì œ ì—”ë“œí¬ì¸íŠ¸
# -----------------------------------------------

@app.post("/quiz/generate")
async def quiz_generate(request: QuizGenerationRequest):
    _, content = combine_vectorstores(request.pdf_paths)
    if not content:
        raise HTTPException(status_code=400, detail="PDF ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨")
    prompt = f"ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {request.num_questions}ê°œ ê°ê´€ì‹ ë¬¸ì œ ìƒì„±, ë‚œì´ë„ {request.difficulty}: {content[:10000]}"
    result = llm.invoke(prompt)
    try:
        questions = json.loads(result.content.strip())
    except:
        questions = [{"question": result.content.strip()}]
    return {"questions": questions}

@app.post("/quiz/grade")
async def quiz_grade(request: QuizGradingRequest):
    """ì‚¬ìš©ìì˜ ë‹µë³€ì„ ì±„ì í•˜ê³  ê²°ê³¼ì™€ ì„¤ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    _, content = combine_vectorstores(request.pdf_paths)
    
    if not content:
        raise HTTPException(status_code=400, detail="PDF ë‚´ìš©ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    results = []
    total_score = 0
    correct_count = 0
    num_total_questions = len(request.answers)
    score_per_question = 100 // num_total_questions if num_total_questions > 0 else 0
    
    for ans in request.answers:
        grade_prompt_text = grading_prompt.format(
            question=ans.question_text,
            user_answer=ans.user_answer,
            context=content[:10000]
        )

        try:
            result = llm.invoke(grade_prompt_text)
            result_text = result.content.strip()

            # LLM ì‘ë‹µì—ì„œ ë°ì´í„° ì¶”ì¶œ
            is_correct_str_match = re.search(r"ì •ë‹µì—¬ë¶€:\s*([^\n]+)", result_text)
            correct_answer_match = re.search(r"ì •ë‹µ:\s*([^\n]+)", result_text, re.DOTALL)
            explanation_match = re.search(r"ì„¤ëª…:\s*([^\n]+)", result_text, re.DOTALL)

            is_correct = "ì •ë‹µ" in is_correct_str_match.group(1).strip() if is_correct_str_match else False
            correct_answer = correct_answer_match.group(1).strip() if correct_answer_match else "ì±„ì  ì˜¤ë¥˜: ì •ë‹µ ë¯¸í¬í•¨"
            explanation = explanation_match.group(1).strip() if explanation_match else "ì±„ì  ì˜¤ë¥˜: ì„¤ëª… ë¯¸í¬í•¨"

            score = score_per_question if is_correct else 0
            total_score += score
            if is_correct:
                correct_count += 1
            
            results.append({
                "question": ans.question_text,
                "user_answer": ans.user_answer,
                "correct_answer": correct_answer,
                "explanation": explanation,
                "is_correct": is_correct,
                "score": score
            })

        except Exception as e:
            logger.error(f"ì±„ì  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            results.append({
                "question": ans.question_text,
                "user_answer": ans.user_answer,
                "correct_answer": "ì‹œìŠ¤í…œ ì˜¤ë¥˜",
                "explanation": f"ì±„ì  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}",
                "is_correct": False,
                "score": 0
            })
            
    # ìµœì¢… ì ìˆ˜ ë³´ì • (100ì  ë§Œì ìœ¼ë¡œ)
    final_total_score = total_score
    remaining_score = 100 - (score_per_question * num_total_questions)
    
    if remaining_score > 0 and correct_count > 0:
        for res in reversed(results):
            if res['is_correct']:
                res['score'] += remaining_score
                final_total_score += remaining_score
                break
    
    if correct_count == 0:
        final_total_score = 0

    return {
        "final_total_score": final_total_score,
        "correct_count": correct_count,
        "total_questions": num_total_questions,
        "results": results
    }